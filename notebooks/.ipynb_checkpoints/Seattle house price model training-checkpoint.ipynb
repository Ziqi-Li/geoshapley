{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Train and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"seattle_samp\")\n",
    "\n",
    "data = data.loc[(data.sqft_lot)<=20000,:]\n",
    "data = data.loc[(data.bedrooms)<=10,:]\n",
    "\n",
    "data[\"age\"] = 2015 - data.yr_built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = gpd.GeoDataFrame(\n",
    "    data, crs=\"EPSG:4326\", geometry=gpd.points_from_xy(x=data.long, y=data.lat))\n",
    "data = data.to_crs(\"EPSG:32610\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[\"UTM_X\"] = data.geometry.x\n",
    "data[\"UTM_Y\"] = data.geometry.y\n",
    "\n",
    "data = data.loc[(data.UTM_X)<=5.7*10**5,:]\n",
    "data = data.loc[(data.UTM_Y)>=5.23*10**6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16581, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampled = data.sample(1000,random_state=1)\n",
    "\n",
    "y = np.log10(sampled.price)\n",
    "\n",
    "X_coords = sampled[['bathrooms', 'sqft_living', 'sqft_lot', 'grade', 'condition',\n",
    "                 'waterfront', 'view', 'age','UTM_X', 'UTM_Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mp/9px298sd6vs8xccb_3sql0dr0000gp/T/ipykernel_56979/2153955958.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_coords[\"log10_price\"] = y\n"
     ]
    }
   ],
   "source": [
    "X_coords[\"log10_price\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_coords.to_csv(\"seattle_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>grade</th>\n",
       "      <th>condition</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>age</th>\n",
       "      <th>UTM_X</th>\n",
       "      <th>UTM_Y</th>\n",
       "      <th>log10_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2660</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>552217.557035</td>\n",
       "      <td>5.274945e+06</td>\n",
       "      <td>6.091315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>2.25</td>\n",
       "      <td>2530</td>\n",
       "      <td>8736</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>565692.484331</td>\n",
       "      <td>5.272758e+06</td>\n",
       "      <td>5.790988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1390</td>\n",
       "      <td>13464</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>562451.661509</td>\n",
       "      <td>5.245291e+06</td>\n",
       "      <td>5.315130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16463</th>\n",
       "      <td>1.00</td>\n",
       "      <td>940</td>\n",
       "      <td>4264</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>546816.935618</td>\n",
       "      <td>5.264407e+06</td>\n",
       "      <td>5.619093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12598</th>\n",
       "      <td>2.25</td>\n",
       "      <td>2070</td>\n",
       "      <td>7225</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>564343.195352</td>\n",
       "      <td>5.244978e+06</td>\n",
       "      <td>5.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13261</th>\n",
       "      <td>1.00</td>\n",
       "      <td>790</td>\n",
       "      <td>13170</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>548381.646974</td>\n",
       "      <td>5.266342e+06</td>\n",
       "      <td>5.447158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2000</td>\n",
       "      <td>5390</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>565755.572522</td>\n",
       "      <td>5.247006e+06</td>\n",
       "      <td>5.453318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>1.75</td>\n",
       "      <td>2160</td>\n",
       "      <td>5760</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>545835.661307</td>\n",
       "      <td>5.264755e+06</td>\n",
       "      <td>5.826075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21213</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1950</td>\n",
       "      <td>1983</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>559976.813626</td>\n",
       "      <td>5.273019e+06</td>\n",
       "      <td>5.894870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>1.50</td>\n",
       "      <td>800</td>\n",
       "      <td>1196</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>549445.306279</td>\n",
       "      <td>5.282856e+06</td>\n",
       "      <td>5.447158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bathrooms  sqft_living  sqft_lot  grade  condition  waterfront  view  \\\n",
       "9172        3.00         2660      4600      8          3           0     0   \n",
       "2264        2.25         2530      8736      7          4           0     0   \n",
       "348         2.00         1390     13464      7          4           0     0   \n",
       "16463       1.00          940      4264      7          5           0     0   \n",
       "12598       2.25         2070      7225      8          3           0     0   \n",
       "...          ...          ...       ...    ...        ...         ...   ...   \n",
       "13261       1.00          790     13170      6          3           0     0   \n",
       "6490        2.50         2000      5390      7          3           0     0   \n",
       "7661        1.75         2160      5760      8          4           0     0   \n",
       "21213       3.00         1950      1983      9          3           0     0   \n",
       "3616        1.50          800      1196      8          3           0     0   \n",
       "\n",
       "       age          UTM_X         UTM_Y  log10_price  \n",
       "9172   109  552217.557035  5.274945e+06     6.091315  \n",
       "2264    57  565692.484331  5.272758e+06     5.790988  \n",
       "348     28  562451.661509  5.245291e+06     5.315130  \n",
       "16463   66  546816.935618  5.264407e+06     5.619093  \n",
       "12598   36  564343.195352  5.244978e+06     5.477121  \n",
       "...    ...            ...           ...          ...  \n",
       "13261   68  548381.646974  5.266342e+06     5.447158  \n",
       "6490    12  565755.572522  5.247006e+06     5.453318  \n",
       "7661    61  545835.661307  5.264755e+06     5.826075  \n",
       "21213    6  559976.813626  5.273019e+06     5.894870  \n",
       "3616    12  549445.306279  5.282856e+06     5.447158  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  54.,  334., 2236., 4665., 4912., 2911.,  975.,  366.,  110.,\n",
       "          18.]),\n",
       " array([4.8920946 , 5.06979823, 5.24750185, 5.42520548, 5.6029091 ,\n",
       "        5.78061273, 5.95831635, 6.13601997, 6.3137236 , 6.49142722,\n",
       "        6.66913085]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGdCAYAAAASUnlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoL0lEQVR4nO3de3BUZZ7/8U8gpAmX7nDLbQgYBxWCXASW0OOVMdI6YUpXUHABWQVdqOAOZORWy4A6swbRGQZHhB1RwpYgwo6XgSyJMZhQCxE0VGYCShY1VnBiB0ZNGhASIM/vDzfnR8vNzoUkPO9XVZf0Od/z5Pn6pMmH06dPwowxRgAAABZo19ITAAAAuFwIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAa4S39ASaS11dnSoqKtS1a1eFhYW19HQAAMAPYIzR0aNHFR8fr3btmv78zBUbfCoqKpSQkNDS0wAAAA1w6NAh9e7du8nHvWKDT9euXSV99z/O7Xa38GwAAMAPEQgElJCQ4Pwcb2pXbPCpf3vL7XYTfAAAaGOa6zIVLm4GAADWIPgAAABrEHwAAIA1CD4AAMAaIQWfJ554QmFhYUGP/v37O/tPnjyptLQ09ejRQ126dNG4ceNUWVkZNEZ5eblSU1PVqVMnRUdHa+7cuTp9+nRQTX5+voYNGyaXy6V+/fopMzOz4R0CAAD8n5DP+AwcOFBffvml8/if//kfZ9+cOXO0ZcsWbd68WQUFBaqoqNC9997r7D9z5oxSU1NVW1urXbt2ad26dcrMzNTixYudmrKyMqWmpmr06NEqLi7W7NmzNX36dOXk5DSyVQAAYLswY4z5ocVPPPGE3nrrLRUXF5+zr7q6Wr169dKGDRs0fvx4SdKBAwc0YMAAFRYWatSoUdq2bZvGjh2riooKxcTESJJWr16t+fPn68iRI4qIiND8+fOVlZWlffv2OWNPnDhRVVVVys7O/sGNBQIBeTweVVdX83F2AADaiOb++R3yGZ+DBw8qPj5eV199tSZNmqTy8nJJUlFRkU6dOqWUlBSntn///urTp48KCwslSYWFhRo0aJATeiTJ5/MpEAho//79Ts3ZY9TX1I9xITU1NQoEAkEPAACAs4UUfJKTk5WZmans7GytWrVKZWVluvnmm3X06FH5/X5FREQoKioq6JiYmBj5/X5Jkt/vDwo99fvr912sJhAI6MSJExecW0ZGhjwej/Pg11UAAIDvC+nOzXfddZfz58GDBys5OVl9+/bVpk2bFBkZ2eSTC8XChQuVnp7uPK+/5TUAAEC9Rn2cPSoqStdee60++eQTxcbGqra2VlVVVUE1lZWVio2NlSTFxsae8ymv+ueXqnG73RcNVy6Xy/n1FPyaCgAAcD6NCj7Hjh3Tp59+qri4OA0fPlwdOnRQXl6es7+0tFTl5eXyer2SJK/Xq5KSEh0+fNipyc3NldvtVlJSklNz9hj1NfVjAAAANFRIwefxxx9XQUGBPv/8c+3atUv/+I//qPbt2+uBBx6Qx+PRtGnTlJ6ervfee09FRUV66KGH5PV6NWrUKEnSmDFjlJSUpClTpugvf/mLcnJytGjRIqWlpcnlckmSZsyYoc8++0zz5s3TgQMH9OKLL2rTpk2aM2dO03cPAACsEtI1Pl988YUeeOABffXVV+rVq5duuukmvf/+++rVq5ckafny5WrXrp3GjRunmpoa+Xw+vfjii87x7du319atWzVz5kx5vV517txZU6dO1VNPPeXUJCYmKisrS3PmzNGKFSvUu3dvrVmzRj6fr4laBgAAtgrpPj5tCffxAX64qxZktfQUQvb50tSWngKAZtDq7uMDAADQVhF8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGuEt/QEgCvNVQuyWnoKAIAL4IwPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWKNRwWfp0qUKCwvT7NmznW0nT55UWlqaevTooS5dumjcuHGqrKwMOq68vFypqanq1KmToqOjNXfuXJ0+fTqoJj8/X8OGDZPL5VK/fv2UmZnZmKkCAAA0PPh88MEH+o//+A8NHjw4aPucOXO0ZcsWbd68WQUFBaqoqNC9997r7D9z5oxSU1NVW1urXbt2ad26dcrMzNTixYudmrKyMqWmpmr06NEqLi7W7NmzNX36dOXk5DR0ugAAAA0LPseOHdOkSZP00ksvqVu3bs726upqvfzyy/rd736nn/70pxo+fLjWrl2rXbt26f3335ckvfPOO/roo4/06quvaujQobrrrrv061//WitXrlRtba0kafXq1UpMTNRvf/tbDRgwQLNmzdL48eO1fPnyJmgZAADYqkHBJy0tTampqUpJSQnaXlRUpFOnTgVt79+/v/r06aPCwkJJUmFhoQYNGqSYmBinxufzKRAIaP/+/U7N98f2+XzOGAAAAA0RHuoBGzdu1N69e/XBBx+cs8/v9ysiIkJRUVFB22NiYuT3+52as0NP/f76fRerCQQCOnHihCIjI8/52jU1NaqpqXGeBwKBUFsDAABXuJDO+Bw6dEi/+MUvtH79enXs2LG55tQgGRkZ8ng8ziMhIaGlpwQAAFqZkIJPUVGRDh8+rGHDhik8PFzh4eEqKCjQ888/r/DwcMXExKi2tlZVVVVBx1VWVio2NlaSFBsbe86nvOqfX6rG7Xaf92yPJC1cuFDV1dXO49ChQ6G0BgAALBBS8Ln99ttVUlKi4uJi5zFixAhNmjTJ+XOHDh2Ul5fnHFNaWqry8nJ5vV5JktfrVUlJiQ4fPuzU5Obmyu12Kykpyak5e4z6mvoxzsflcsntdgc9AAAAzhbSNT5du3bV9ddfH7Stc+fO6tGjh7N92rRpSk9PV/fu3eV2u/XYY4/J6/Vq1KhRkqQxY8YoKSlJU6ZM0bJly+T3+7Vo0SKlpaXJ5XJJkmbMmKEXXnhB8+bN08MPP6zt27dr06ZNysrKaoqeAQCApUK+uPlSli9frnbt2mncuHGqqamRz+fTiy++6Oxv3769tm7dqpkzZ8rr9apz586aOnWqnnrqKacmMTFRWVlZmjNnjlasWKHevXtrzZo18vl8TT1dAABgkTBjjGnpSTSHQCAgj8ej6upq3vbCZXXVAs5MXg6fL01t6SkAaAbN/fOb39UFAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBohBZ9Vq1Zp8ODBcrvdcrvd8nq92rZtm7P/5MmTSktLU48ePdSlSxeNGzdOlZWVQWOUl5crNTVVnTp1UnR0tObOnavTp08H1eTn52vYsGFyuVzq16+fMjMzG94hAADA/wkp+PTu3VtLly5VUVGRPvzwQ/30pz/V3Xffrf3790uS5syZoy1btmjz5s0qKChQRUWF7r33Xuf4M2fOKDU1VbW1tdq1a5fWrVunzMxMLV682KkpKytTamqqRo8ereLiYs2ePVvTp09XTk5OE7UMAABsFWaMMY0ZoHv37nr22Wc1fvx49erVSxs2bND48eMlSQcOHNCAAQNUWFioUaNGadu2bRo7dqwqKioUExMjSVq9erXmz5+vI0eOKCIiQvPnz1dWVpb27dvnfI2JEyeqqqpK2dnZP3hegUBAHo9H1dXVcrvdjWkRCMlVC7JaegpW+HxpaktPAUAzaO6f3w2+xufMmTPauHGjjh8/Lq/Xq6KiIp06dUopKSlOTf/+/dWnTx8VFhZKkgoLCzVo0CAn9EiSz+dTIBBwzhoVFhYGjVFfUz/GhdTU1CgQCAQ9AAAAzhZy8CkpKVGXLl3kcrk0Y8YMvfnmm0pKSpLf71dERISioqKC6mNiYuT3+yVJfr8/KPTU76/fd7GaQCCgEydOXHBeGRkZ8ng8ziMhISHU1gAAwBUu5OBz3XXXqbi4WLt379bMmTM1depUffTRR80xt5AsXLhQ1dXVzuPQoUMtPSUAANDKhId6QEREhPr16ydJGj58uD744AOtWLFCEyZMUG1traqqqoLO+lRWVio2NlaSFBsbqz179gSNV/+pr7Nrvv9JsMrKSrndbkVGRl5wXi6XSy6XK9R2AACARRp9H5+6ujrV1NRo+PDh6tChg/Ly8px9paWlKi8vl9frlSR5vV6VlJTo8OHDTk1ubq7cbreSkpKcmrPHqK+pHwMAAKChQjrjs3DhQt11113q06ePjh49qg0bNig/P185OTnyeDyaNm2a0tPT1b17d7ndbj322GPyer0aNWqUJGnMmDFKSkrSlClTtGzZMvn9fi1atEhpaWnO2ZoZM2bohRde0Lx58/Twww9r+/bt2rRpk7Ky+KQMAABonJCCz+HDh/Xggw/qyy+/lMfj0eDBg5WTk6M77rhDkrR8+XK1a9dO48aNU01NjXw+n1588UXn+Pbt22vr1q2aOXOmvF6vOnfurKlTp+qpp55yahITE5WVlaU5c+ZoxYoV6t27t9asWSOfz9dELQMAAFs1+j4+rRX38UFL4T4+lwf38QGuTM398zvki5sBoDVoiwGTsAa0PH5JKQAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBrhLT0B4GKuWpDV0lMAAFxBOOMDAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDVCCj4ZGRn6h3/4B3Xt2lXR0dG65557VFpaGlRz8uRJpaWlqUePHurSpYvGjRunysrKoJry8nKlpqaqU6dOio6O1ty5c3X69Omgmvz8fA0bNkwul0v9+vVTZmZmwzoEAAD4PyEFn4KCAqWlpen9999Xbm6uTp06pTFjxuj48eNOzZw5c7RlyxZt3rxZBQUFqqio0L333uvsP3PmjFJTU1VbW6tdu3Zp3bp1yszM1OLFi52asrIypaamavTo0SouLtbs2bM1ffp05eTkNEHLAADAVmHGGNPQg48cOaLo6GgVFBTolltuUXV1tXr16qUNGzZo/PjxkqQDBw5owIABKiws1KhRo7Rt2zaNHTtWFRUViomJkSStXr1a8+fP15EjRxQREaH58+crKytL+/btc77WxIkTVVVVpezs7B80t0AgII/Ho+rqarnd7oa2iBZ21YKslp4C0GQ+X5ra0lMAWr3m/vndqGt8qqurJUndu3eXJBUVFenUqVNKSUlxavr3768+ffqosLBQklRYWKhBgwY5oUeSfD6fAoGA9u/f79ScPUZ9Tf0Y51NTU6NAIBD0AAAAOFuDg09dXZ1mz56tG2+8Uddff70kye/3KyIiQlFRUUG1MTEx8vv9Ts3Zoad+f/2+i9UEAgGdOHHivPPJyMiQx+NxHgkJCQ1tDQAAXKEaHHzS0tK0b98+bdy4sSnn02ALFy5UdXW18zh06FBLTwkAALQy4Q05aNasWdq6dat27Nih3r17O9tjY2NVW1urqqqqoLM+lZWVio2NdWr27NkTNF79p77Orvn+J8EqKyvldrsVGRl53jm5XC65XK6GtAMAACwR0hkfY4xmzZqlN998U9u3b1diYmLQ/uHDh6tDhw7Ky8tztpWWlqq8vFxer1eS5PV6VVJSosOHDzs1ubm5crvdSkpKcmrOHqO+pn4MAACAhgjpjE9aWpo2bNigt99+W127dnWuyfF4PIqMjJTH49G0adOUnp6u7t27y+1267HHHpPX69WoUaMkSWPGjFFSUpKmTJmiZcuWye/3a9GiRUpLS3PO2MyYMUMvvPCC5s2bp4cffljbt2/Xpk2blJXFJ3wAAEDDhXTGZ9WqVaqurtZtt92muLg45/H66687NcuXL9fYsWM1btw43XLLLYqNjdUbb7zh7G/fvr22bt2q9u3by+v1avLkyXrwwQf11FNPOTWJiYnKyspSbm6uhgwZot/+9rdas2aNfD5fE7QMAABs1aj7+LRm3MfnysB9fHAl4T4+wKW16vv4AAAAtCUEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYI+Tgs2PHDv385z9XfHy8wsLC9NZbbwXtN8Zo8eLFiouLU2RkpFJSUnTw4MGgmq+//lqTJk2S2+1WVFSUpk2bpmPHjgXV/PWvf9XNN9+sjh07KiEhQcuWLQu9OwAAgLOEHHyOHz+uIUOGaOXKlefdv2zZMj3//PNavXq1du/erc6dO8vn8+nkyZNOzaRJk7R//37l5uZq69at2rFjhx599FFnfyAQ0JgxY9S3b18VFRXp2Wef1RNPPKE//vGPDWgRAADgO2HGGNPgg8PC9Oabb+qee+6R9N3Znvj4eP3yl7/U448/Lkmqrq5WTEyMMjMzNXHiRH388cdKSkrSBx98oBEjRkiSsrOz9bOf/UxffPGF4uPjtWrVKv3bv/2b/H6/IiIiJEkLFizQW2+9pQMHDvyguQUCAXk8HlVXV8vtdje0RbSwqxZktfQUgCbz+dLUlp4C0Oo198/vJr3Gp6ysTH6/XykpKc42j8ej5ORkFRYWSpIKCwsVFRXlhB5JSklJUbt27bR7926n5pZbbnFCjyT5fD6Vlpbqm2++acopAwAAi4Q35WB+v1+SFBMTE7Q9JibG2ef3+xUdHR08ifBwde/ePagmMTHxnDHq93Xr1u2cr11TU6OamhrneSAQaGQ3AADgSnPFfKorIyNDHo/HeSQkJLT0lAAAQCvTpGd8YmNjJUmVlZWKi4tztldWVmro0KFOzeHDh4OOO336tL7++mvn+NjYWFVWVgbV1D+vr/m+hQsXKj093XkeCAQIPwBalbZ4zRrXJeFK06RnfBITExUbG6u8vDxnWyAQ0O7du+X1eiVJXq9XVVVVKioqcmq2b9+uuro6JScnOzU7duzQqVOnnJrc3Fxdd911532bS5JcLpfcbnfQAwAA4GwhB59jx46puLhYxcXFkr67oLm4uFjl5eUKCwvT7Nmz9Zvf/EZ//vOfVVJSogcffFDx8fHOJ78GDBigO++8U4888oj27NmjnTt3atasWZo4caLi4+MlSf/0T/+kiIgITZs2Tfv379frr7+uFStWBJ3RAQAACFXIb3V9+OGHGj16tPO8PoxMnTpVmZmZmjdvno4fP65HH31UVVVVuummm5Sdna2OHTs6x6xfv16zZs3S7bffrnbt2mncuHF6/vnnnf0ej0fvvPOO0tLSNHz4cPXs2VOLFy8OutcPAABAqBp1H5/WjPv4XBna4jURwJWEa3xwubWp+/gAAAC0ZgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWIPgAAABrEHwAAIA1CD4AAMAaBB8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGuEt/QEAACt11ULslp6CiH7fGlqS08BrRhnfAAAgDU442OJtvivNgAAmhpnfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArEHwAQAA1iD4AAAAaxB8AACANQg+AADAGgQfAABgDYIPAACwBsEHAABYg+ADAACsQfABAADWCG/pCQAA0JSuWpDV0lMI2edLU1t6CtbgjA8AALAGwQcAAFiD4AMAAKzRqq/xWblypZ599ln5/X4NGTJEf/jDHzRy5MiWnlabfP8YAAC04jM+r7/+utLT07VkyRLt3btXQ4YMkc/n0+HDh1t6agAAoI1qtcHnd7/7nR555BE99NBDSkpK0urVq9WpUye98sorLT01AADQRrXKt7pqa2tVVFSkhQsXOtvatWunlJQUFRYWnveYmpoa1dTUOM+rq6slSYFAoMnnV1fzbZOPCQCwV585m1t6CiHb96SvWcat/7ltjGmW8Vtl8Pn73/+uM2fOKCYmJmh7TEyMDhw4cN5jMjIy9OSTT56zPSEhoVnmCACAzTy/b97xjx49Ko/H0+Tjtsrg0xALFy5Uenq687yurk5ff/21evToobCwsBacWeMEAgElJCTo0KFDcrvdLT2dy8rm3iW7+7e5d8nu/undzt6l/99/eXm5wsLCFB8f3yxfp1UGn549e6p9+/aqrKwM2l5ZWanY2NjzHuNyueRyuYK2RUVFNdcULzu3223lC0Gyu3fJ7v5t7l2yu396t7N3SfJ4PM3af6u8uDkiIkLDhw9XXl6es62urk55eXnyer0tODMAANCWtcozPpKUnp6uqVOnasSIERo5cqR+//vf6/jx43rooYdaemoAAKCNarXBZ8KECTpy5IgWL14sv9+voUOHKjs7+5wLnq90LpdLS5YsOedtPBvY3Ltkd/829y7Z3T+929m7dPn6DzPN9XkxAACAVqZVXuMDAADQHAg+AADAGgQfAABgDYIPAACwBsHnMnriiScUFhYW9Ojfv/9Fj9m8ebP69++vjh07atCgQfrv//7voP3GGC1evFhxcXGKjIxUSkqKDh482JxtNEiovb/00ku6+eab1a1bN3Xr1k0pKSnas2dPUM0///M/nzPmnXfe2dythCzU3jMzM8+p79ixY1BNW1l3KfT+b7vttnPqw8LClJqa6tS0lbWXpL/97W+aPHmyevToocjISA0aNEgffvjhRY/Jz8/XsGHD5HK51K9fP2VmZp5Ts3LlSl111VXq2LGjkpOTz3l9tBah9v/GG2/ojjvuUK9eveR2u+X1epWTkxNU05C/S1tCqL3n5+ef93vf7/cH1bWFtQ+19/O9psPCwjRw4ECnpqnWvdV+nP1KNXDgQL377rvO8/DwCy/Brl279MADDygjI0Njx47Vhg0bdM8992jv3r26/vrrJUnLli3T888/r3Xr1ikxMVG/+tWv5PP59NFHH53zw7KlhdJ7fn6+HnjgAf3kJz9Rx44d9cwzz2jMmDHav3+/fvSjHzl1d955p9auXes8b60fAw2ld+m7O7eWlpY6z7//a1fa0rpLofX/xhtvqLa21nn+1VdfaciQIbrvvvuC6trC2n/zzTe68cYbNXr0aG3btk29evXSwYMH1a1btwseU1ZWptTUVM2YMUPr169XXl6epk+frri4OPl83/1SyNdff13p6elavXq1kpOT9fvf/14+n0+lpaWKjo6+XO1dUkP637Fjh+644w49/fTTioqK0tq1a/Xzn/9cu3fv1g033ODUhfqautwa0nu90tLSoDsXn72mbWHtG9L7ihUrtHTpUuf56dOnz/u6b5J1N7hslixZYoYMGfKD6++//36TmpoatC05Odn8y7/8izHGmLq6OhMbG2ueffZZZ39VVZVxuVzmtddea5I5N5VQe/++06dPm65du5p169Y526ZOnWruvvvuxk+umYXa+9q1a43H47ng/ra07sY0fu2XL19uunbtao4dO+ZsaytrP3/+fHPTTTeFdMy8efPMwIEDg7ZNmDDB+Hw+5/nIkSNNWlqa8/zMmTMmPj7eZGRkNG7CTawh/Z9PUlKSefLJJ53njf2euhwa0vt7771nJJlvvvnmgjVtYe2bYt3ffPNNExYWZj7//HNnW1OtO291XWYHDx5UfHy8rr76ak2aNEnl5eUXrC0sLFRKSkrQNp/Pp8LCQknf/cvQ7/cH1Xg8HiUnJzs1rUkovX/ft99+q1OnTql79+5B2/Pz8xUdHa3rrrtOM2fO1FdffdXU024SofZ+7Ngx9e3bVwkJCbr77ru1f/9+Z19bW3epcWv/8ssva+LEiercuXPQ9raw9n/+8581YsQI3XfffYqOjtYNN9ygl1566aLHXOp1X1tbq6KioqCadu3aKSUlpdWtf0P6/766ujodPXr0nNd+Y76nLofG9D506FDFxcXpjjvu0M6dO53tbWXtm2LdX375ZaWkpKhv375B25ti3Qk+l1FycrIyMzOVnZ2tVatWqaysTDfffLOOHj163nq/33/OnapjYmKc93vr/3uxmtYi1N6/b/78+YqPjw96wd955536z//8T+Xl5emZZ55RQUGB7rrrLp05c6a52miQUHu/7rrr9Morr+jtt9/Wq6++qrq6Ov3kJz/RF198IaltrbvUuLXfs2eP9u3bp+nTpwdtbytr/9lnn2nVqlW65pprlJOTo5kzZ+pf//VftW7dugsec6HXfSAQ0IkTJ/T3v/9dZ86caRPr35D+v++5557TsWPHdP/99zvbGvv3yeXQkN7j4uK0evVq/elPf9Kf/vQnJSQk6LbbbtPevXslqc2sfWPXvaKiQtu2bTvndd9k697oc0ZosG+++ca43W6zZs2a8+7v0KGD2bBhQ9C2lStXmujoaGOMMTt37jSSTEVFRVDNfffdZ+6///7mmXQTuVTvZ8vIyDDdunUzf/nLXy5a9+mnnxpJ5t13322qaTaLUHo3xpja2lrz4x//2CxatMgY07bX3ZjQ+n/00UfNoEGDLlnXWte+Q4cOxuv1Bm177LHHzKhRoy54zDXXXGOefvrpoG1ZWVlGkvn222/N3/72NyPJ7Nq1K6hm7ty5ZuTIkU03+SbQkP7Ptn79etOpUyeTm5t70bpQX1OXQ2N7r3fLLbeYyZMnG2NMm1n7xvb+9NNPmx49epiampqL1jV03Tnj04KioqJ07bXX6pNPPjnv/tjYWFVWVgZtq6ysVGxsrLO/ftuFalqrS/Ve77nnntPSpUv1zjvvaPDgwRetvfrqq9WzZ89LjtnSfmjv9Tp06KAbbrjBqW/L6y798P6PHz+ujRs3atq0aZccs7WufVxcnJKSkoK2DRgw4KKn5y/0une73YqMjFTPnj3Vvn37NrH+Dem/3saNGzV9+nRt2rTpnLf+vi/U19Tl0JjezzZy5Einr7ay9o3p3RijV155RVOmTFFERMRFaxu67gSfFnTs2DF9+umniouLO+9+r9ervLy8oG25ubnyer2SpMTERMXGxgbVBAIB7d6926lprS7Vu/TdJ5d+/etfKzs7WyNGjLjkmF988YW++uqri47ZGvyQ3s925swZlZSUOPVted2lH97/5s2bVVNTo8mTJ19yzNa69jfeeGPQp/Mk6X//93/PuW7hbJd63UdERGj48OFBNXV1dcrLy2t169+Q/iXptdde00MPPaTXXnst6DYGFxLqa+pyaGjv31dcXOz01VbWvjG9FxQU6JNPPvlB/+Bp8LqHdH4IjfLLX/7S5Ofnm7KyMrNz506TkpJievbsaQ4fPmyMMWbKlClmwYIFTv3OnTtNeHi4ee6558zHH39slixZYjp06GBKSkqcmqVLl5qoqCjz9ttvm7/+9a/m7rvvNomJiebEiROXvb+LCbX3pUuXmoiICPNf//Vf5ssvv3QeR48eNcYYc/ToUfP444+bwsJCU1ZWZt59910zbNgwc80115iTJ0+2SI8XEmrvTz75pMnJyTGffvqpKSoqMhMnTjQdO3Y0+/fvd2rayrobE3r/9W666SYzYcKEc7a3pbXfs2ePCQ8PN//+7/9uDh486Lx18+qrrzo1CxYsMFOmTHGef/bZZ6ZTp05m7ty55uOPPzYrV6407du3N9nZ2U7Nxo0bjcvlMpmZmeajjz4yjz76qImKijJ+v/+y9ncpDel//fr1Jjw83KxcuTLotV9VVeXUXOp7qjVoSO/Lly83b731ljl48KApKSkxv/jFL0y7du2C3sJtC2vfkN7rTZ482SQnJ5933KZad4LPZTRhwgQTFxdnIiIizI9+9CMzYcIE88knnzj7b731VjN16tSgYzZt2mSuvfZaExERYQYOHGiysrKC9tfV1Zlf/epXJiYmxrhcLnP77beb0tLSy9FOSELtvW/fvkbSOY8lS5YYY4z59ttvzZgxY0yvXr1Mhw4dTN++fc0jjzzSql789ULtffbs2aZPnz4mIiLCxMTEmJ/97Gdm7969QWO2lXU3pmHf9wcOHDCSzDvvvHPOeG1p7Y0xZsuWLeb66683LpfL9O/f3/zxj38M2j916lRz6623Bm177733zNChQ01ERIS5+uqrzdq1a88Z9w9/+IPzfTJy5Ejz/vvvN2MXDRdq/7feeut5X/tnf49c6nuqtQi192eeecb8+Mc/Nh07djTdu3c3t912m9m+ffs547aFtW/I931VVZWJjIw8p7ZeU617mDHGhHaOCAAAoG3iGh8AAGANgg8AALAGwQcAAFiD4AMAAKxB8AEAANYg+AAAAGsQfAAAgDUIPgAAwBoEHwAAYA2CDwAAsAbBBwAAWIPgAwAArPH/AKnEIoKkOq0CAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mp/9px298sd6vs8xccb_3sql0dr0000gp/T/ipykernel_78464/2260372218.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('coolwarm',8),vmin=-1,vmax=1,fmt=\".2f\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10),dpi=80)\n",
    "\n",
    "dataplot = sns.heatmap(X_coords.corr(),annot=True,square=True,\n",
    "                       cmap = plt.cm.get_cmap('coolwarm',8),vmin=-1,vmax=1,fmt=\".2f\")\n",
    "#plt.savefig(\"coor_matrix_house.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_coords, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, random_forest_regressor,mlp_regressor,svr,any_preprocessing\n",
    "from hpsklearn import xgboost_regression,gaussian_process_regressor,linear_regression\n",
    "from hyperopt import tpe\n",
    "from sklearn.metrics import r2_score\n",
    "from hyperopt import STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_any_model(any_regressor,  max_evals=100):\n",
    "    \n",
    "    estim = HyperoptEstimator(regressor=any_regressor(\"myModel\"),\n",
    "                              algo=tpe.suggest,max_evals=max_evals,\n",
    "                              trial_timeout=60,seed=999)\n",
    "    \n",
    "    estim.fit(X_train.values, y_train.values)\n",
    "    \n",
    "    return estim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.12s/trial, best loss: 0.24225102603110282]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.11s/trial, best loss: 0.24225102603110193]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.10s/trial, best loss: 0.24225102603110193]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.10s/trial, best loss: 0.24225102603110193]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.16s/trial, best loss: 0.2422510176230661]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.18s/trial, best loss: 0.2422510176230661]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.06s/trial, best loss: 0.2422510176230661]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.12s/trial, best loss: 0.2422510176230661]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.16s/trial, best loss: 0.2422510176230661]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.08s/trial, best loss: 0.2422510176230661]\n",
      "CPU times: user 137 ms, sys: 110 ms, total: 247 ms\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ols_model = train_any_model(linear_regression,max_evals=10)\n",
    "#pickle.dump(ols_model, open(\"ols_house.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762883934343102\n"
     ]
    }
   ],
   "source": [
    "print(ols_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/trial, best loss: 459.3845321761294]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.16s/trial, best loss: 0.19564789085757872]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.12770803911661033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.06s/trial, best loss: 0.12770803911661033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.12s/trial, best loss: 0.12770803911661033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.13s/trial, best loss: 0.12770803911661033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.12770803911661033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.21s/trial, best loss: 0.12770803911661033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  2.06s/trial, best loss: 0.10435181088400358]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.10435181088400358]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.10s/trial, best loss: 0.10435181088400358]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.09867178761240847]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.52s/trial, best loss: 0.09867178761240847]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.09867178761240847]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.27s/trial, best loss: 0.09867178761240847]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  2.80s/trial, best loss: 0.09733363624347757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.98s/trial, best loss: 0.09733363624347757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.35s/trial, best loss: 0.09733363624347757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:52<00:00, 52.41s/trial, best loss: 0.09733363624347757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.14s/trial, best loss: 0.09733363624347757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.10s/trial, best loss: 0.09733363624347757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:02<00:00,  2.55s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00,  2.33s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:29<00:00, 29.30s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  6.35s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  2.39s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00,  2.29s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:04<00:00,  4.69s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:02<00:00,  2.32s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [01:35<00:00, 95.41s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.89s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00,  2.29s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:03<00:00,  3.31s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  3.64s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00,  2.26s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  6.92s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:02<00:00,  2.22s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00,  1.65s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:12<00:00, 12.22s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:04<00:00,  4.00s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:03<00:00,  3.64s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:01<00:00,  1.88s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:02<00:00,  2.38s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.96s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:02<00:00,  2.63s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:11<00:00, 11.12s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:02<00:00,  2.82s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00,  4.25s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:01<00:00,  1.84s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00,  2.46s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [15:50<00:00, 950.85s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:02<00:00,  2.41s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:01<00:00,  1.71s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [15:00<00:00, 900.54s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:02<00:00,  2.46s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [17:26<00:00, 1046.79s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:02<00:00,  2.04s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [07:15<00:00, 435.90s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:01<00:00,  1.76s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:01<00:00,  1.55s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:01<00:00,  1.64s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:01<00:00,  1.63s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:01<00:00,  1.36s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:01<00:00,  1.82s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00,  3.59s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:02<00:00,  2.23s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00,  2.12s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:02<00:00,  2.42s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:03<00:00,  3.14s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:01<00:00,  1.68s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:03<00:00,  3.04s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:01<00:00,  1.96s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:02<00:00,  2.07s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00,  2.04s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:06<00:00,  6.20s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:02<00:00,  2.04s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:01<00:00,  1.79s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:02<00:00,  2.28s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00,  1.88s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:01<00:00,  1.76s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:02<00:00,  2.26s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:01<00:00,  1.58s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:02<00:00,  2.59s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:03<00:00,  3.32s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:04<00:00,  4.52s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:03<00:00,  3.85s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:02<00:00,  2.34s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:01<00:00,  1.90s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00,  2.17s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:01<00:00,  1.95s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:01<00:00,  1.75s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:01<00:00,  1.88s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [00:02<00:00,  2.47s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:02<00:00,  2.09s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:03<00:00,  3.49s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:04<00:00,  4.54s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:01<00:00,  1.86s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:03<00:00,  3.76s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:04<00:00,  4.53s/trial, best loss: 0.09529817320876]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00,  1.85s/trial, best loss: 0.09529817320876]\n",
      "CPU times: user 4.44 s, sys: 2.93 s, total: 7.37 s\n",
      "Wall time: 1h 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = train_any_model(xgboost_regression)\n",
    "pickle.dump(xgb_model, open(\"xgb_house.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.19s/trial, best loss: 29473.413882657696]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  3.86s/trial, best loss: 29473.413882657696]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00, 11.36s/trial, best loss: 0.24223213013229883]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  5.12s/trial, best loss: 0.24223213013229883]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.79s/trial, best loss: 0.24223213013229883]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:14<00:00, 14.97s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  3.51s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  7.00s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.48s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  3.15s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:04<00:00,  4.32s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.65s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:00<00:00, 60.96s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:04<00:00,  4.69s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  4.62s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  3.04s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:04<00:00,  4.52s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [01:01<00:00, 61.02s/trial, best loss: 0.18083745167506837]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  3.49s/trial, best loss: 0.14689932415832152]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:03<00:00,  3.77s/trial, best loss: 0.1468235918177544]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:03<00:00,  3.59s/trial, best loss: 0.1468235918177544]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:03<00:00,  3.45s/trial, best loss: 0.1468235918177544]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  3.14s/trial, best loss: 0.1468235918177544]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  3.25s/trial, best loss: 0.13662872085211564]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  2.64s/trial, best loss: 0.13662872085211564]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.61s/trial, best loss: 0.13662872085211564]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:03<00:00,  3.36s/trial, best loss: 0.1361737560070223]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:03<00:00,  3.32s/trial, best loss: 0.1361737560070223]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00,  2.81s/trial, best loss: 0.1361737560070223]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:02<00:00,  2.51s/trial, best loss: 0.1361737560070223]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:04<00:00,  4.98s/trial, best loss: 0.1361737560070223]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:03<00:00,  3.32s/trial, best loss: 0.1361737560070223]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:02<00:00,  2.91s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00,  2.55s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00,  2.65s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:02<00:00,  2.31s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:02<00:00,  2.20s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:03<00:00,  3.25s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00,  2.16s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:02<00:00,  2.96s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:04<00:00,  4.56s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:02<00:00,  2.72s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:02<00:00,  2.17s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:03<00:00,  3.72s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.86s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:03<00:00,  3.50s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:03<00:00,  3.27s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:02<00:00,  3.00s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:00<00:00, 60.99s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:01<00:00,  1.91s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:02<00:00,  2.40s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:03<00:00,  3.42s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:02<00:00,  2.15s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:02<00:00,  2.59s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:03<00:00,  3.55s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:01<00:00, 61.03s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:01<00:00,  1.76s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:03<00:00,  3.69s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:01<00:00,  1.76s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00,  3.55s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:05<00:00,  5.95s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:04<00:00,  4.47s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:03<00:00,  3.02s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00,  3.26s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:03<00:00,  3.55s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:03<00:00,  3.76s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:03<00:00,  3.12s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:03<00:00,  3.06s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:03<00:00,  3.76s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:02<00:00,  2.96s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:03<00:00,  3.03s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:02<00:00,  2.71s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:03<00:00,  3.24s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:04<00:00,  4.98s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:02<00:00,  2.77s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:02<00:00,  2.36s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:02<00:00,  2.88s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:25<00:00, 25.79s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00,  2.93s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:05<00:00,  5.20s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:03<00:00,  3.66s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:02<00:00,  2.55s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:02<00:00,  2.72s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:02<00:00,  2.38s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:17<00:00, 17.81s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:02<00:00,  2.66s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00,  4.60s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00,  2.59s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00,  3.83s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:03<00:00,  3.02s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:02<00:00,  2.30s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [00:02<00:00,  2.60s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:02<00:00,  2.66s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:05<00:00,  5.69s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:02<00:00,  2.33s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:01<00:00,  1.80s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:02<00:00,  2.67s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:02<00:00,  2.93s/trial, best loss: 0.13444157333913598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00,  4.94s/trial, best loss: 0.13444157333913598]\n",
      "CPU times: user 3.87 s, sys: 1.52 s, total: 5.39 s\n",
      "Wall time: 10min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_model = train_any_model(svr)\n",
    "pickle.dump(svm_model, open(\"svm_house.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  8.27s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  8.25s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  8.40s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:08<00:00,  8.14s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:08<00:00,  8.49s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  8.41s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  8.07s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  8.42s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  8.42s/trial, best loss: 0.8705720321487401]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  8.39s/trial, best loss: 0.17427354052430155]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  8.25s/trial, best loss: 0.17427354052430155]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:08<00:00,  8.46s/trial, best loss: 0.17427354052430155]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  8.07s/trial, best loss: 0.17427354052430155]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  8.08s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:07<00:00,  7.74s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:08<00:00,  8.65s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:08<00:00,  8.41s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:08<00:00,  8.68s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:08<00:00,  8.50s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  8.13s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:08<00:00,  8.76s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:08<00:00,  8.08s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:08<00:00,  8.44s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  8.15s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:08<00:00,  8.19s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:08<00:00,  8.19s/trial, best loss: 0.1337033980590988]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  7.91s/trial, best loss: 0.1334870693296908]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:09<00:00,  9.16s/trial, best loss: 0.1334870693296908]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  8.30s/trial, best loss: 0.1334870693296908]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  8.60s/trial, best loss: 0.1334870693296908]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:08<00:00,  8.59s/trial, best loss: 0.1334870693296908]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:08<00:00,  8.48s/trial, best loss: 0.13344177853236938]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  8.76s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:08<00:00,  8.71s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:08<00:00,  8.46s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:08<00:00,  8.58s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:08<00:00,  8.35s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:08<00:00,  8.31s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  8.01s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:07<00:00,  7.92s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:08<00:00,  8.54s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:08<00:00,  8.55s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:08<00:00,  8.41s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:08<00:00,  8.50s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:08<00:00,  8.11s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:08<00:00,  8.33s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:08<00:00,  8.43s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:08<00:00,  8.47s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:08<00:00,  8.64s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:08<00:00,  8.51s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:08<00:00,  8.52s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:08<00:00,  8.34s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:08<00:00,  8.52s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:08<00:00,  8.63s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  8.36s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:09<00:00,  9.02s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:07<00:00,  7.93s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:07<00:00,  7.79s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:08<00:00,  8.08s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.98s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:07<00:00,  7.85s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:07<00:00,  7.56s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:07<00:00,  7.95s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:07<00:00,  7.99s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:08<00:00,  8.47s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.59s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:07<00:00,  7.87s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:08<00:00,  8.09s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:07<00:00,  7.89s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:07<00:00,  7.80s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:07<00:00,  7.94s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.04s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:08<00:00,  8.54s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:08<00:00,  8.76s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:07<00:00,  7.82s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:07<00:00,  7.79s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:08<00:00,  8.95s/trial, best loss: 0.1334411395291295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:08<00:00,  8.15s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:07<00:00,  7.58s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:07<00:00,  7.97s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:07<00:00,  7.79s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:08<00:00,  8.10s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:08<00:00,  8.07s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:07<00:00,  7.68s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:08<00:00,  8.54s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:08<00:00,  8.17s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:07<00:00,  7.94s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:07<00:00,  7.84s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:07<00:00,  7.71s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:07<00:00,  7.89s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:08<00:00,  8.02s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [00:07<00:00,  7.73s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:08<00:00,  8.03s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:07<00:00,  7.88s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:08<00:00,  8.04s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:07<00:00,  7.82s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:07<00:00,  7.95s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:07<00:00,  7.71s/trial, best loss: 0.13342566643842135]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00,  7.90s/trial, best loss: 0.13342566643842135]\n",
      "CPU times: user 58.2 s, sys: 11.2 s, total: 1min 9s\n",
      "Wall time: 13min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gp_model = train_any_model(gaussian_process_regressor)\n",
    "pickle.dump(gp_model, open(\"gp_house.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.68s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  8.30s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00, 12.02s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.49s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00<00:00, 60.92s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.56s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:00<00:00, 60.87s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:50<00:00, 50.45s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.56s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [01:00<00:00, 60.89s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:04<00:00,  4.43s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  6.53s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  8.89s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:06<00:00,  6.54s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:44<00:00, 44.31s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:46<00:00, 46.41s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:23<00:00, 23.64s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.93s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.19s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.76s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.24s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00,  2.65s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.27s/trial, best loss: 0.11599220581344716]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:06<00:00,  6.47s/trial, best loss: 0.11589209193965233]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:03<00:00,  3.37s/trial, best loss: 0.11564035077234303]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:03<00:00,  3.19s/trial, best loss: 0.11560940321322566]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:06<00:00,  6.85s/trial, best loss: 0.11536423166643028]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  7.65s/trial, best loss: 0.11536423166643028]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:07<00:00,  7.58s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:21<00:00, 21.22s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:06<00:00,  6.21s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:22<00:00, 22.23s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00,  1.87s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00, 19.81s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:20<00:00, 20.26s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:41<00:00, 41.98s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:16<00:00, 16.88s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:00<00:00, 60.87s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:28<00:00, 28.49s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:01<00:00,  1.52s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [01:00<00:00, 60.86s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.67s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:07<00:00,  7.62s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [01:00<00:00, 60.87s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:08<00:00,  8.50s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:00<00:00, 60.93s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:21<00:00, 21.03s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:10<00:00, 10.68s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [01:00<00:00, 60.83s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [01:00<00:00, 60.91s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:06<00:00,  6.19s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:19<00:00, 19.98s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:02<00:00,  2.26s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:02<00:00,  2.42s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:16<00:00, 16.05s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:54<00:00, 54.40s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:13<00:00, 13.88s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:01<00:00,  1.19s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:16<00:00, 16.68s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [01:00<00:00, 60.94s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:01<00:00,  1.76s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:05<00:00,  5.21s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00,  6.28s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:18<00:00, 18.90s/trial, best loss: 0.115320363746098]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:17<00:00, 17.81s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:10<00:00, 10.39s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:13<00:00, 13.23s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:19<00:00, 19.17s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:37<00:00, 37.64s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:05<00:00,  5.54s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:27<00:00, 27.16s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:03<00:00,  3.99s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:01<00:00,  1.40s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:06<00:00,  6.54s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:10<00:00, 10.99s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:03<00:00,  3.78s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00,  1.74s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:00<00:00, 60.89s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:18<00:00, 18.41s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:05<00:00,  5.97s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:17<00:00, 17.60s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [01:00<00:00, 60.86s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:14<00:00, 14.39s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:31<00:00, 31.35s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:07<00:00,  7.41s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:01<00:00,  1.68s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:43<00:00, 43.10s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:07<00:00,  7.87s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:13<00:00, 13.25s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:03<00:00,  3.98s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [01:00<00:00, 60.86s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:04<00:00,  4.10s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:02<00:00,  2.04s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:19<00:00, 19.58s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:33<00:00, 33.25s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [01:00<00:00, 60.90s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:33<00:00, 33.71s/trial, best loss: 0.11529387338327379]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:16<00:00, 16.98s/trial, best loss: 0.11529387338327379]\n",
      "CPU times: user 23.7 s, sys: 3.36 s, total: 27.1 s\n",
      "Wall time: 33min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = train_any_model(random_forest_regressor)\n",
    "pickle.dump(rf_model, open(\"rf_house.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762883934343102\n",
      "0.8918709082832037\n",
      "0.9080845209772526\n",
      "0.8675981660295368\n",
      "0.8686325530577202\n"
     ]
    }
   ],
   "source": [
    "print(ols_model.score(X_test, y_test))\n",
    "print(rf_model.score(X_test, y_test))\n",
    "print(xgb_model.score(X_test, y_test))\n",
    "print(svm_model.score(X_test, y_test))\n",
    "print(gp_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.55s/trial, best loss: 0.29735952163097923]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.29735952163097923]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (265) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.41s/trial, best loss: 0.9260528110277542]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.40s/trial, best loss: 0.2656441731079753]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.2656441731079753]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.43s/trial, best loss: 0.2656441731079753]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.31s/trial, best loss: 0.2656441731079753]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.11s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.13s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.22s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.41s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.99s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.40s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.26s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.35s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.37s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.38s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.14s/trial, best loss: 0.141129043716116]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/21 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.29s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.89s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.53s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.17s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  2.89s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.69s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.64s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.32s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.44s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.39s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.41s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.91s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:02<00:00,  2.69s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:01<00:00,  1.29s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00,  1.55s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00,  1.59s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00,  1.73s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:04<00:00,  4.20s/trial, best loss: 0.141129043716116]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 38/39 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00,  1.53s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.58s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:01<00:00,  1.42s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:02<00:00,  2.06s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:01<00:00,  1.53s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.56s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:01<00:00,  1.99s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.32s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:01<00:00,  1.36s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:01<00:00,  1.24s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:02<00:00,  2.60s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00,  1.84s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:01<00:00,  1.51s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:01<00:00,  1.58s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:01<00:00,  1.47s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:03<00:00,  3.76s/trial, best loss: 0.141129043716116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:01<00:00,  1.27s/trial, best loss: 0.141129043716116]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 55/56 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (232) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 55/56 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.5882623147304293]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.5882623147304293]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  5.14s/trial, best loss: 0.5882623147304293]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.55s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.51s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.56s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.35s/trial, best loss: 0.21917235186425987]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:03<00:00,  3.53s/trial, best loss: 0.21917235186425987]\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 12/13 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  2.04s/trial, best loss: 0.19774602235319982]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.19774602235319982]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.39s/trial, best loss: 0.19774602235319982]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.47s/trial, best loss: 0.19359494010791323]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.84s/trial, best loss: 0.19359494010791323]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.19359494010791323]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.15089190131287822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  5.47s/trial, best loss: 0.15089190131287822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.50s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  2.53s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.89s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.76s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:02<00:00,  2.69s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00,  2.10s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.96s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.30s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:02<00:00,  2.13s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:01<00:00,  1.67s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00,  2.27s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00,  2.16s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00,  1.63s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00,  1.43s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00,  1.75s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.59s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:01<00:00,  1.73s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:01<00:00,  1.93s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:01<00:00,  1.71s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.60s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:01<00:00,  1.23s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.43s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:01<00:00,  1.72s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:01<00:00,  1.66s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:01<00:00,  1.56s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00,  2.53s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:01<00:00,  1.66s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:01<00:00,  1.94s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:01<00:00,  1.32s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:01<00:00,  1.56s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:01<00:00,  1.82s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00,  1.56s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:01<00:00,  1.77s/trial, best loss: 0.1429184992460375]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:01<00:00,  1.61s/trial, best loss: 0.1429184992460375]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/59 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (325) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/59 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.22s/trial, best loss: 598.8439068190571]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.14879394330489815]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44s/trial, best loss: 0.14879394330489815]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.46s/trial, best loss: 0.14879394330489815]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (191) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.2133569661287842]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  2.91s/trial, best loss: 0.2133569661287842]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.2133569661287842]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.29s/trial, best loss: 0.2133569661287842]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (235) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:07<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.50s/trial, best loss: 1.6177107923492757]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32s/trial, best loss: 1.0007969491861204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.52s/trial, best loss: 0.30209979775683204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.96s/trial, best loss: 0.20289474695927112]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.71s/trial, best loss: 0.18463680928138504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.64s/trial, best loss: 0.18463680928138504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.43s/trial, best loss: 0.18463680928138504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  5.30s/trial, best loss: 0.18463680928138504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.1717541261169161]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.51s/trial, best loss: 0.1717541261169161]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.88s/trial, best loss: 0.1717541261169161]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.1717541261169161]\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 12/13 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (191) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 12/13 [00:03<?, ?trial/s, best loss=?]\n",
      "  0%|                                     | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (152) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 0/1 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.02s/trial, best loss: 52.203506581265906]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24s/trial, best loss: 1.0000000060535033]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.996369158123479]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.20233442475297192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.20233442475297192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.20233442475297192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.20233442475297192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.20233442475297192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.20233442475297192]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (192) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/10 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/trial, best loss: 0.2837763928387419]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  2.90s/trial, best loss: 0.2837763928387419]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.45s/trial, best loss: 0.28040377530203897]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.21501027044217924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.32s/trial, best loss: 0.21501027044217924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.44s/trial, best loss: 0.21501027044217924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.21501027044217924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.00s/trial, best loss: 0.1984355876975782]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.55s/trial, best loss: 0.1984355876975782]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.1984355876975782]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.52s/trial, best loss: 0.1984355876975782]\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11/12 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (304) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11/12 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.57s/trial, best loss: 1.1149442482556102]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  2.04s/trial, best loss: 1.1149442482556102]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.40s/trial, best loss: 1.0357702635666823]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.49s/trial, best loss: 0.9997410385181568]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (161) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.39s/trial, best loss: 0.4222289382945049]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  3.86s/trial, best loss: 0.4222289382945049]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.4222289382945049]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.40s/trial, best loss: 0.27205610557132354]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.27205610557132354]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.55s/trial, best loss: 0.27205610557132354]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.27205610557132354]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  6.17s/trial, best loss: 0.27205610557132354]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.47s/trial, best loss: 0.2357374038483233]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  4.06s/trial, best loss: 0.2357374038483233]\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.53s/trial, best loss: 0.2357374038483233]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.2357374038483233]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.39s/trial, best loss: 0.16120128065543693]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.28s/trial, best loss: 0.16120128065543693]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.16120128065543693]\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15/16 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (166) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15/16 [00:02<?, ?trial/s, best loss=?]\n",
      "  0%|                                     | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (242) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 0/1 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.16257453801575972]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.16257453801575972]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.16257453801575972]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.37s/trial, best loss: 0.16257453801575972]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.16257453801575972]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.45s/trial, best loss: 0.16257453801575972]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.1612615728338853]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.1612615728338853]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.1612615728338853]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1612615728338853]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.23s/trial, best loss: 0.1612615728338853]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.1612615728338853]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.33s/trial, best loss: 0.1612615728338853]\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 13/14 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (211) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 13/14 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  8.09s/trial, best loss: 0.23631051399587877]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.27s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.51s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.87s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.38s/trial, best loss: 0.23631051399587877]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.23631051399587877]\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (191) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.64s/trial, best loss: 1.0509797402689673]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.48s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.33s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.43s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.14705467536905192]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.46s/trial, best loss: 0.14705467536905192]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (295) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/10 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/trial, best loss: 0.24718389700135768]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.24718389700135768]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  3.72s/trial, best loss: 0.24718389700135768]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (343) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.07s/trial, best loss: 1794.5761026603177]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  6.32s/trial, best loss: 1794.5761026603177]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2622677428353175]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  4.01s/trial, best loss: 0.22789228603688094]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.22789228603688094]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.52s/trial, best loss: 0.19441856889229758]\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.54s/trial, best loss: 1.0443293895455015]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (231) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  2.98s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.53s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.52s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.19s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.21s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  2.38s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  2.38s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.46s/trial, best loss: 0.2431010413976924]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.88s/trial, best loss: 0.16414651228792076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.09s/trial, best loss: 0.16414651228792076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.85s/trial, best loss: 0.16414651228792076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.54s/trial, best loss: 0.16414651228792076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.91s/trial, best loss: 0.16414651228792076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.16414651228792076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.55s/trial, best loss: 0.16137566788482427]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00,  2.01s/trial, best loss: 0.13858607401213607]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.13858607401213607]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 25/26 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (170) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 25/26 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.27554288003031013]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  3.13s/trial, best loss: 0.27554288003031013]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2207197802525831]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.2207197802525831]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.38s/trial, best loss: 0.2207197802525831]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:06<00:00,  6.14s/trial, best loss: 0.2207197802525831]\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (206) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.8077227403537685]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.28s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.20s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  5.81s/trial, best loss: 0.1390446882683306]\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.31s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.52s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  5.06s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:04<00:00,  4.31s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.21s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.93s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  2.00s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  3.18s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.51s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.34s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.71s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:02<00:00,  2.69s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.50s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.67s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.78s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.86s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00,  1.72s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:02<00:00,  2.04s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00,  1.52s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00,  1.50s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00,  1.44s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00,  1.67s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00,  2.08s/trial, best loss: 0.1390446882683306]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.88s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:01<00:00,  1.62s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:01<00:00,  1.26s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:02<00:00,  2.02s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.64s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:02<00:00,  2.28s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.67s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:01<00:00,  1.65s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:06<00:00,  6.75s/trial, best loss: 0.1307177157525613]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 48/49 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (288) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:01<00:00,  1.25s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00,  1.85s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:01<00:00,  1.69s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:01<00:00,  1.31s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:01<00:00,  1.71s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:01<00:00,  1.69s/trial, best loss: 0.1307177157525613]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:01<00:00,  1.45s/trial, best loss: 0.1307177157525613]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 55/56 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (230) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 55/56 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/trial, best loss: 1.0087108282639707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.48s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  1.02trial/s, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  7.09s/trial, best loss: 0.34866327810761866]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:06<00:00,  6.64s/trial, best loss: 0.34866327810761866]\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  3.38s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.34s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.39s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  2.42s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.34866327810761866]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.38s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.35s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.50s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.34s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.48s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.44s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.44s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.46s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.40s/trial, best loss: 0.17879060477924213]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.43s/trial, best loss: 0.17879060477924213]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (180) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/25 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.49s/trial, best loss: 7.395318898577678]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26s/trial, best loss: 0.928406548913116]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.22106956906466357]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.22106956906466357]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.50s/trial, best loss: 0.22106956906466357]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.13s/trial, best loss: 0.22106956906466357]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.52s/trial, best loss: 0.22106956906466357]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.19464006981916204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.32s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.32s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.53s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.24s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.57s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.88s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.87s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  4.00s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.81s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.82s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.1583757142488369]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.85s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  2.63s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.88s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.74s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.83s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.80s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.30s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.46s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00,  1.41s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  5.63s/trial, best loss: 0.13299993374518038]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 34/35 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (244) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:07<00:00,  7.71s/trial, best loss: 0.13299993374518038]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 35/36 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00,  1.59s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00,  1.81s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00,  1.49s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00,  1.63s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.90s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:01<00:00,  1.49s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:03<00:00,  3.84s/trial, best loss: 0.13299993374518038]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/43 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:01<00:00,  1.39s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.43s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:01<00:00,  1.39s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.30s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:01<00:00,  1.43s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:01<00:00,  1.47s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:01<00:00,  1.67s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00,  1.45s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:04<00:00,  4.08s/trial, best loss: 0.13299993374518038]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 51/52 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (160) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:01<00:00,  1.72s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:01<00:00,  1.47s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:01<00:00,  1.65s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:01<00:00,  1.44s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00,  1.58s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:03<00:00,  3.90s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00,  2.24s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:01<00:00,  1.39s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:01<00:00,  1.41s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:01<00:00,  1.77s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:01<00:00,  1.77s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:01<00:00,  1.52s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:02<00:00,  2.04s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:01<00:00,  1.64s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:01<00:00,  1.76s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00,  1.77s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:01<00:00,  1.85s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:01<00:00,  1.73s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:01<00:00,  1.89s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:01<00:00,  1.79s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:01<00:00,  1.81s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:01<00:00,  1.86s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:01<00:00,  1.85s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:01<00:00,  1.98s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:01<00:00,  1.40s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:01<00:00,  1.51s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:01<00:00,  1.61s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00,  1.61s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:01<00:00,  1.85s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00,  1.98s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:01<00:00,  1.57s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:01<00:00,  1.73s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:01<00:00,  1.56s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:01<00:00,  1.43s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:01<00:00,  1.72s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:01<00:00,  1.56s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:01<00:00,  1.88s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:01<00:00,  1.60s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:01<00:00,  1.78s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:01<00:00,  1.55s/trial, best loss: 0.13299993374518038]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:01<00:00,  1.88s/trial, best loss: 0.13299993374518038]\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/93 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (257) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/93 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.58s/trial, best loss: 1.0097143842507723]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  6.58s/trial, best loss: 1.0097143842507723]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.33s/trial, best loss: 0.2942239582857632]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.2942239582857632]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.37s/trial, best loss: 0.2942239582857632]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.04s/trial, best loss: 0.2942239582857632]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.26423647294653374]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.26423647294653374]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.26423647294653374]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  4.86s/trial, best loss: 0.26423647294653374]\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (215) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (238) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/trial, best loss: 1.1608196059587745]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (288) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.59s/trial, best loss: 1463.9658076499447]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.54s/trial, best loss: 103.37431954410786]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (256) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/trial, best loss: 1.0291047628404404]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.715777164627866]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (190) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.21549105742039043]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.21549105742039043]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  2.05s/trial, best loss: 0.21549105742039043]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.07s/trial, best loss: 0.21549105742039043]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.26s/trial, best loss: 0.21549105742039043]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.20s/trial, best loss: 0.21549105742039043]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.51s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.47s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:03<00:00,  3.28s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.54s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.48s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:07<00:00,  7.04s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.34s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.50s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.50s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.56s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  2.29s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.79s/trial, best loss: 0.1716525138456262]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.56s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.41s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.78s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.57s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.54s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.59s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.65s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.64s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:02<00:00,  2.29s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:01<00:00,  1.41s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00,  2.11s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00,  1.54s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00,  1.49s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00,  1.46s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00,  1.96s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.63s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:02<00:00,  2.09s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:01<00:00,  1.47s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:01<00:00,  1.63s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.69s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:01<00:00,  1.51s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.58s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:01<00:00,  1.68s/trial, best loss: 0.1463234774717198]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:02<00:00,  2.23s/trial, best loss: 0.1463234774717198]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 48/49 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (311) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 48/49 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.396981790646887]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36s/trial, best loss: 0.27806979021673595]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.27806979021673595]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.48s/trial, best loss: 0.27806979021673595]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.1801614692984267]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.1801614692984267]\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (277) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:08<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/trial, best loss: 1.0259203596561375e+89]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (171) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 1/2 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/trial, best loss: 0.9274254871413048]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91s/trial, best loss: 0.8466976368839482]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.31s/trial, best loss: 0.8466976368839482]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.20s/trial, best loss: 0.2806609607227031]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.2806609607227031]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.21s/trial, best loss: 0.2806609607227031]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.98s/trial, best loss: 0.2806609607227031]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.14s/trial, best loss: 0.2528894457723445]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.07s/trial, best loss: 0.2528894457723445]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.22s/trial, best loss: 0.2528894457723445]\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.28s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.23s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  4.66s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:07<00:00,  7.78s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.30s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  6.21s/trial, best loss: 0.16532254356236686]\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 17/18 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.25s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  2.79s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  2.32s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.24s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.16532254356236686]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.16532254356236686]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (266) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/25 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.78s/trial, best loss: 11244.092939842065]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  3.89s/trial, best loss: 0.15314787664734353]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.16s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  5.34s/trial, best loss: 0.15314787664734353]\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.55s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.46s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:05<00:00,  5.90s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  2.56s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.32s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.20s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.13s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.22s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.26s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.10s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.10s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.10s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.19s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.57s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.91s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.32s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.70s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.42s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.72s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.38s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00,  1.92s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:02<00:00,  2.60s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00,  2.53s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00,  1.31s/trial, best loss: 0.15314787664734353]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:02<00:00,  2.52s/trial, best loss: 0.15314787664734353]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 37/38 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (253) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 37/38 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.9902084343514553]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25s/trial, best loss: 0.3375894733164295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.34s/trial, best loss: 0.3375894733164295]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.3375894733164295]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (287) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.87s/trial, best loss: 0.24508089668340727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.24508089668340727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.24508089668340727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.35s/trial, best loss: 0.24508089668340727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.29s/trial, best loss: 0.24508089668340727]\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (265) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 5/6 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.6453401461602482]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.51s/trial, best loss: 0.41170668623301954]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.31s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.28s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.43s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.17s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.18s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  2.66s/trial, best loss: 0.26553289265519264]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.25s/trial, best loss: 0.25837371746090565]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.23637593885538888]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.12s/trial, best loss: 0.23637593885538888]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.36s/trial, best loss: 0.23637593885538888]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.55s/trial, best loss: 0.19367026862058911]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.51s/trial, best loss: 0.19367026862058911]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.45s/trial, best loss: 0.19367026862058911]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.06s/trial, best loss: 0.19367026862058911]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.44s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.54s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.88s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.46s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.63s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.46s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.47s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.44s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.41s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00,  2.78s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.37s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.44s/trial, best loss: 0.12841745627976786]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.32s/trial, best loss: 0.1254825279158409]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 30/31 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (255) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 30/31 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.31s/trial, best loss: 0.9966198827529656]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  2.16s/trial, best loss: 0.32678454535037404]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.48s/trial, best loss: 0.32678454535037404]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.28s/trial, best loss: 0.23212287138701426]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.1767051551092822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.50s/trial, best loss: 0.1767051551092822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.1767051551092822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.24s/trial, best loss: 0.1767051551092822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.46s/trial, best loss: 0.1767051551092822]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.49s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.31s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  6.12s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  2.43s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.21s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.37s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.18s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  6.47s/trial, best loss: 0.17429558407395707]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (318) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.39s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.18s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.32s/trial, best loss: 0.17429558407395707]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.46s/trial, best loss: 0.1713124002171723]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.47s/trial, best loss: 0.16524342842661233]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.56s/trial, best loss: 0.16513341606228282]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.53s/trial, best loss: 0.16513341606228282]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.47s/trial, best loss: 0.16513341606228282]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.53s/trial, best loss: 0.16513341606228282]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.52s/trial, best loss: 0.16513341606228282]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (262) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/30 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/trial, best loss: 0.2949111204382442]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99s/trial, best loss: 0.2949111204382442]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.2949111204382442]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.29s/trial, best loss: 0.2949111204382442]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.48s/trial, best loss: 0.25501608963639844]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.25501608963639844]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.33s/trial, best loss: 0.20100162790528076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.11s/trial, best loss: 0.20100162790528076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.31s/trial, best loss: 0.20100162790528076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.11s/trial, best loss: 0.20100162790528076]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.34s/trial, best loss: 0.1578363276489606]\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11/12 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (193) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11/12 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.28s/trial, best loss: 0.24782363868261204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.24782363868261204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.24s/trial, best loss: 0.24782363868261204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.39s/trial, best loss: 0.24782363868261204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  7.96s/trial, best loss: 0.24782363868261204]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.48s/trial, best loss: 0.228141964982141]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  6.17s/trial, best loss: 0.228141964982141]\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/8 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.15s/trial, best loss: 0.228141964982141]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  2.05s/trial, best loss: 0.228141964982141]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.52s/trial, best loss: 0.228141964982141]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.27s/trial, best loss: 0.228141964982141]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.228141964982141]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.33s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.62s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.35s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.27s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.40s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.56s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.32s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.40s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.33s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.66s/trial, best loss: 0.1858462666037657]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:04<00:00,  4.97s/trial, best loss: 0.18486966584295605]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.43s/trial, best loss: 0.18486966584295605]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:04<00:00,  4.36s/trial, best loss: 0.17400339438704593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  4.15s/trial, best loss: 0.17400339438704593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:03<00:00,  3.73s/trial, best loss: 0.17400339438704593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  3.95s/trial, best loss: 0.17400339438704593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:03<00:00,  3.68s/trial, best loss: 0.17400339438704593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:01<00:00,  1.49s/trial, best loss: 0.17400339438704593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:04<00:00,  4.21s/trial, best loss: 0.17400339438704593]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 35/36 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (169) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:04<00:00,  4.31s/trial, best loss: 0.17302386692468774]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:04<00:00,  4.51s/trial, best loss: 0.17302386692468774]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 37/38 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (257) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:03<00:00,  3.90s/trial, best loss: 0.15995904957736562]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:04<00:00,  4.03s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.61s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:03<00:00,  3.92s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:03<00:00,  3.59s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:03<00:00,  3.97s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.55s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:01<00:00,  1.40s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:02<00:00,  2.50s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:03<00:00,  3.09s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:01<00:00,  1.37s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:02<00:00,  2.54s/trial, best loss: 0.12457284092736498]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00,  1.78s/trial, best loss: 0.12457284092736498]\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 50/51 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (330) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 50/51 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.15185874556394008]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41s/trial, best loss: 0.15185874556394008]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.45s/trial, best loss: 0.15185874556394008]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (221) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.33s/trial, best loss: 0.3676127003731524]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.03s/trial, best loss: 0.3676127003731524]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.16s/trial, best loss: 0.3676127003731524]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  5.78s/trial, best loss: 0.20964312480341074]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (211) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.25s/trial, best loss: 0.20964312480341074]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  3.90s/trial, best loss: 0.20964312480341074]\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (158) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/trial, best loss: 1.075060790843531]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24s/trial, best loss: 1.0661435112089819]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.15s/trial, best loss: 1.0008200060068706]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.34s/trial, best loss: 0.5516825290020749]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.50s/trial, best loss: 0.5516825290020749]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.22048710119043546]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.20s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.14s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.33s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.18s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.45s/trial, best loss: 0.16923303632797504]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.28s/trial, best loss: 0.16923303632797504]\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15/16 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (164) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15/16 [00:02<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.16186840747624598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.17s/trial, best loss: 0.16186840747624598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.27s/trial, best loss: 0.16186840747624598]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  4.82s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.20s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.07s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.40s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  4.57s/trial, best loss: 0.14220686532570126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.33s/trial, best loss: 0.14220686532570126]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:05<00:00,  5.65s/trial, best loss: 0.12297876211670156]\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 12/13 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (278) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.26s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.04s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.43s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:02<00:00,  2.54s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:02<00:00,  2.28s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.48s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.79s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.79s/trial, best loss: 0.12297876211670156]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.24s/trial, best loss: 0.12297876211670156]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/23 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (187) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  5.13s/trial, best loss: 0.12297876211670156]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/24 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (182) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:05<00:00,  5.47s/trial, best loss: 0.12297876211670156]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (349) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/25 [00:05<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/trial, best loss: 1.0248763366839537]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44s/trial, best loss: 1.0102708956562136]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.13s/trial, best loss: 0.9993865008259226]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.9993865008259226]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.2727155247861137]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.43s/trial, best loss: 0.2727155247861137]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.25s/trial, best loss: 0.2727155247861137]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2727155247861137]\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 8/9 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (223) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 8/9 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.85s/trial, best loss: 1.0498065546529587]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3269044839731259]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  5.35s/trial, best loss: 0.3269044839731259]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.22s/trial, best loss: 0.3269044839731259]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.42s/trial, best loss: 0.3269044839731259]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.50s/trial, best loss: 0.24530644879184105]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.56s/trial, best loss: 0.24530644879184105]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.24530644879184105]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  2.80s/trial, best loss: 0.24530644879184105]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.11s/trial, best loss: 0.24530644879184105]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  2.00s/trial, best loss: 0.1696768644077289]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.47s/trial, best loss: 0.1696768644077289]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.43s/trial, best loss: 0.1696768644077289]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.1696768644077289]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  3.62s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.47s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.52s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.05s/trial, best loss: 0.12654323245411547]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:03<00:00,  3.68s/trial, best loss: 0.12594707556211215]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:03<00:00,  3.52s/trial, best loss: 0.1254783278609738]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  3.83s/trial, best loss: 0.1254783278609738]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  3.07s/trial, best loss: 0.1254783278609738]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  3.60s/trial, best loss: 0.12375325422053962]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/27 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (211) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/27 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/trial, best loss: 0.4166979022767616]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.52s/trial, best loss: 0.1394648092059143]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  2.97s/trial, best loss: 0.1394648092059143]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (316) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.05trial/s, best loss: 0.9949320535981682]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.42s/trial, best loss: 0.21889607669740085]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.21889607669740085]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.34s/trial, best loss: 0.21889607669740085]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.1357977244317926]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.41s/trial, best loss: 0.1357977244317926]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.20s/trial, best loss: 0.1357977244317926]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.23s/trial, best loss: 0.1357977244317926]\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 8/9 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (198) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 8/9 [00:03<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/trial, best loss: 0.2278990095287351]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.37s/trial, best loss: 0.2278990095287351]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.44s/trial, best loss: 0.2278990095287351]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.2278990095287351]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.42s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  4.49s/trial, best loss: 0.19517258433305762]\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.52s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.41s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.21s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.50s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.43s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.49s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.33s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.42s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  2.69s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.13s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:02<00:00,  2.97s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  2.17s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.40s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.50s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.31s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.45s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.19517258433305762]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.43s/trial, best loss: 0.13704214120421132]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  3.60s/trial, best loss: 0.1290906629424189]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:04<00:00,  4.29s/trial, best loss: 0.1290906629424189]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 27/28 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (224) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:04<00:00,  4.83s/trial, best loss: 0.12415849620650132]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/29 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (244) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (256) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/29 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.54s/trial, best loss: 1.000185208634487]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.23s/trial, best loss: 0.24926047526158546]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  8.16s/trial, best loss: 0.24926047526158546]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.24s/trial, best loss: 0.24267456672269172]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.20s/trial, best loss: 0.24267456672269172]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.39s/trial, best loss: 0.14053436228056593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.14053436228056593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.24s/trial, best loss: 0.14053436228056593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.14053436228056593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.80s/trial, best loss: 0.14053436228056593]\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (181) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:06<00:00,  6.81s/trial, best loss: 0.14053436228056593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.07s/trial, best loss: 0.14053436228056593]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.14053436228056593]\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 13/14 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z**2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (316) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 13/14 [00:06<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  4.25s/trial, best loss: 0.35147522814943843]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.48s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.45s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.45s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.18s/trial, best loss: 0.35147522814943843]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.45s/trial, best loss: 0.22227508612987945]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.14s/trial, best loss: 0.22227508612987945]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.47s/trial, best loss: 0.1511820619933476]\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11/12 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (195) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11/12 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/trial, best loss: 11.09913406117929]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22s/trial, best loss: 0.5428194669834241]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.15s/trial, best loss: 0.37791762720425437]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.22s/trial, best loss: 0.37791762720425437]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (190) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 4/5 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.11s/trial, best loss: 0.9552721247481692]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  2.89s/trial, best loss: 0.9552721247481692]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.41s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.31s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.54s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.35s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.32s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  1.49s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.48s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.17s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.41s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  3.03s/trial, best loss: 0.15517739644188921]\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15/16 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (158) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  6.21s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.37s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:02<00:00,  2.19s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  1.21s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.28s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.51s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:02<00:00,  2.10s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.47s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.54s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.41s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.50s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.44s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.55s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.89s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.43s/trial, best loss: 0.15517739644188921]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.45s/trial, best loss: 0.15517739644188921]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 31/32 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (272) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "job exception: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 31/32 [00:04<?, ?trial/s, best loss=?]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.6489680337069339]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.02s/trial, best loss: 0.6489680337069339]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.37s/trial, best loss: 0.2574892364758108]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  1.40s/trial, best loss: 0.2574892364758108]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  1.29s/trial, best loss: 0.2574892364758108]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  1.39s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  1.15s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  7.17s/trial, best loss: 0.19474745561758278]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  1.48s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  1.56s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  1.13s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00,  1.40s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  1.25s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  1.21s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  1.48s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00,  1.54s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:05<00:00,  5.23s/trial, best loss: 0.19474745561758278]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziqili/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00,  1.19s/trial, best loss: 0.19474745561758278]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.1634510484160454]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00,  1.45s/trial, best loss: 0.1634510484160454]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00,  1.54s/trial, best loss: 0.1634510484160454]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00,  1.41s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00,  1.39s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00,  1.48s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00,  1.50s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:01<00:00,  1.37s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00,  1.35s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00,  1.60s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:01<00:00,  1.46s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00,  1.57s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00,  1.97s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:01<00:00,  1.72s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00,  1.48s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00,  1.65s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00,  1.41s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00,  1.45s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00,  1.34s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00,  1.52s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:01<00:00,  1.22s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:01<00:00,  1.63s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:01<00:00,  1.37s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:01<00:00,  1.43s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:01<00:00,  1.42s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:01<00:00,  1.37s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:01<00:00,  1.38s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:01<00:00,  1.43s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:02<00:00,  2.28s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00,  1.44s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:01<00:00,  1.43s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:01<00:00,  1.29s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:01<00:00,  1.68s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:02<00:00,  2.65s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:01<00:00,  1.27s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00,  1.33s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:01<00:00,  1.64s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:01<00:00,  1.19s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:01<00:00,  1.40s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:01<00:00,  1.91s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:01<00:00,  1.31s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:01<00:00,  1.76s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:01<00:00,  1.41s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:01<00:00,  1.43s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:01<00:00,  1.26s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:01<00:00,  1.41s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00,  2.01s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:01<00:00,  1.56s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:01<00:00,  1.47s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:01<00:00,  1.57s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:01<00:00,  1.64s/trial, best loss: 0.14042587980325183]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:01<00:00,  1.61s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:01<00:00,  1.96s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:02<00:00,  2.04s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:01<00:00,  1.57s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:01<00:00,  1.40s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:01<00:00,  1.23s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:01<00:00,  1.50s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00,  1.93s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:01<00:00,  1.66s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00,  1.65s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:01<00:00,  1.42s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:01<00:00,  1.39s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:01<00:00,  1.55s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:01<00:00,  1.25s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:01<00:00,  1.41s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:01<00:00,  1.53s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:01<00:00,  1.45s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:01<00:00,  1.47s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:01<00:00,  1.43s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:02<00:00,  2.80s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:01<00:00,  1.60s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [00:01<00:00,  1.56s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:01<00:00,  1.30s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:01<00:00,  1.31s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:01<00:00,  1.42s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:01<00:00,  1.34s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:01<00:00,  1.95s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:01<00:00,  1.47s/trial, best loss: 0.13128558162338533]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00,  1.26s/trial, best loss: 0.13128558162338533]\n",
      "CPU times: user 29.8 s, sys: 12.3 s, total: 42.1 s\n",
      "Wall time: 35min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for i in range(0,1000):\n",
    "    try:\n",
    "        mlp_model = train_any_model(mlp_regressor)\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8583345080845761\n"
     ]
    }
   ],
   "source": [
    "print(mlp_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mlp_model, open(\"mlp_house.sav\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
